{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amir reza 81\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amir reza 81\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Amir Reza 81\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for tehran...\n",
      "Extracting data for kerman...\n",
      "Extracting data for yazd...\n",
      "Extracting data for isfahan...\n",
      "Extracting data for alborz...\n",
      "Extracting data for qom...\n",
      "Extracting data for fars...\n",
      "Extracting data for azarbaijan_sharghi...\n",
      "Extracting data for golestan...\n",
      "Extracting data for semnan...\n",
      "Scraping complete! Data saved to samand_cars_all_cities.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "cities = [\n",
    "    \"tehran\", \"kerman\", \"yazd\", \"isfahan\", \"alborz\", \n",
    "    \"qom\", \"fars\", \"azarbaijan_sharghi\", \"golestan\", \"semnan\"\n",
    "]\n",
    "\n",
    "all_car_data = []\n",
    "\n",
    "def extract_car_data(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch the page {url}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    car_data = []\n",
    "\n",
    "    cars = soup.find_all(\"div\", class_=\"bama-ad-holder\")\n",
    "\n",
    "    for car in cars:\n",
    "        try:\n",
    "            price = car.find(\"span\", class_=\"bama-ad__price\").text.strip() if car.find(\"span\", class_=\"bama-ad__price\") else \"N/A\"\n",
    "\n",
    "            details = car.find(\"div\", class_=\"bama-ad__detail-row\").text.strip()\n",
    "            details_parts = [d.strip() for d in details.split(\"\\n\") if d.strip()]\n",
    "\n",
    "            production_year = details_parts[0] if len(details_parts) > 0 else \"N/A\"\n",
    "            mileage = details_parts[1] if len(details_parts) > 1 else \"N/A\"\n",
    "            type = details_parts[2] if len(details_parts) > 2 else \"N/A\"\n",
    "\n",
    "            car_data.append([\n",
    "                price, mileage, production_year, type\n",
    "            ])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error extracting data:\", e)\n",
    "\n",
    "    return car_data\n",
    "\n",
    "for city in cities:\n",
    "    print(f\"Extracting data for {city}...\")\n",
    "    url = f\"https://bama.ir/car/samand/{city}?priced=1&seller=1\"\n",
    "    city_car_data = extract_car_data(url)\n",
    "    all_car_data.extend(city_car_data)\n",
    "\n",
    "df = pd.DataFrame(all_car_data, columns=[\n",
    "    \"Price\", \"Mileage\", \"Production Year\", \"Type\"\n",
    "])\n",
    "\n",
    "df.to_excel(\"samand_cars_all_cities.xlsx\", index=False)\n",
    "\n",
    "print(\"Scraping complete! Data saved to samand_cars_all_cities.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
